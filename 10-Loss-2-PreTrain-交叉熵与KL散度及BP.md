<!-- JPW的Markdown笔记模板 v1, 其中的href需要视情更改上级目录href="../../format.css -->
<link rel="stylesheet" type="text/css" href="../../format.css">


<h1>LLMs系列进阶：预训练损失Loss与反向传播BP</h1>

💡 深度学习模型的训练思路基于反向传播原理（Back Propagation），即初始化模型参数后进行前向计算（预测），对预测结果和标签计算损失（距离），然后基于微分分摊损失责任到所有参数上进行更新。不断重复，直到损失变得足够小。LLMs主流采用decoder-only架构，这种架构根据之前时间步的token序列迭代生成next token，是一个典型的判别式多分类任务模型。因此主流的模型预训练方法中采用最小多元交叉熵优化作为极大似然估计的实例。

损失函数通常是根据模型的目标任务（如语言建模、分类、回归等）来设计的。不同大模型基座的核心区别之一就是如何设计损失函数。例如自回归的生成模型的目标就是要让$P(y|x, y < t)$的概率最大化，即根据当前时间步的输入x和之前时间步的y为条件，使得当前时间步的y的条件概率最大化，具体实现上对于一句长度为T的话，通常是计算完T个token的损失取平均后进行序列级BP，如下，R是正则化项（如权重衰减L2和Dropout）：
$$
L = -\frac{1}{T}\sum_{t=1}^T \log p(x_t|x_1, x_2,..., x_{t-1}) + \lambda R
$$
其中，为了保证训练稳定性，逐个自回归过程采用teacher forcing，及采用标签序列中的实际token作为previous序列，而非生成的。

本章主要内容包括：
- 熵
- 交叉熵
- 相对熵（KL散度）
- 交叉熵与KL散度区别
- 多元交叉熵的BP流程

在了解交叉熵之前，需要了解什么是熵，以及另一个伴生概念KL散度
# 1 熵：信息量
熵是信息理论中的一个度量，表示一个随机变量的不确定性或信息量。熵越高，表示系统越不确定，信息量越大；熵越低，表示系统的状态越确定，信息量越小。对于离散的随机变量X而言，其熵$H(X)$的计算公式为：
$$H(X) = -\sum_{i=1}^{N}p(y_i)\log p(y_i)$$

其中，$-\log p_{y_i}$表示事件$y_i$的信息量，即当i事件发生时，如果其**本身发生的概率越小，则其一旦发生所蕴含的信息量越大**，即作为一个0-1范围内的概率值，其越小，经过负对数后值越大。

进一步，如果我们有一个含有N个事件的系统，那么这个系统所包含的信息量应该是所有事件的信息量之和。但考虑到不同事件发生的概率本身不同，因此再乘以其本身发生的概率作为权重，也即对于事件$y_i$，其对系统贡献的加权后的信息量为$-p_{y_i}\log p_{y_i}$。最后，所有N个事件的加权信息量之和就表示总体信息量，即**不同事件的概率和它们对系统不确定性的贡献**。

熵本质上衡量了一个随机变量的不确定性或混乱程度，**熵越大，意味着系统的不确定性越高，越难预测**。那么什么情况下一个系统/随机变量的熵最大呢？熵最大，即表示系统最不确定，即所有事件发生的概率一致（没有任何事件更可能发生）。因此当所有$p(y_i)=\frac{1}{N}$时熵最大，等于$\log n$。一旦其中一件事发生的概率变大，那么其他事件发生的概率变小，系统就更确定了一点，熵减小。

# 2 交叉熵：概率分布差异
cross entropy。从上可知，**熵代表一个系统/随机变量的概率分布的不确定性**，而**交叉熵则代表两个概率分布之间的差异**。这通常用于衡量真实分布与预测分布之间的差异，即对于含有N个事件的系统而言：
$$ H(p,q) = -\sum_{i=1}^{N}p(y_i)\log q(y_i)$$

事件$y_i$的交叉熵表示为$-p(y_i)\log \hat{p}(y_i)$，当两个概率一致时，预测分布的信息量等于真实分布；否则，**交叉熵一定大于熵**，因为预测分布如果和真实分布不同，那么用预测分布来描述真实世界时往往会多出一些额外信息，即**KL散度**。

交叉熵损失常用于分类任务，而语言建模任务的本质（预测next token）也是分类，即生成词表空间的概率分布预测。

具体而言，对于next token生成式任务：
- 真实标签：一个长度等于词表空间的概率分布向量（one-hot形式），其中真实的next token处为1，其余为0。
- 预测结果：一个长度等于词表空间的概率分布向量，值是每个词作为next token的概率，通常经过softmax在输出层激活进行归一化。

此时的损失值只需要计算所有词的总损失即可，如下：
$$\text{Loss} = -\sum_{i=1}^{\text{VocabSize}}p(y_i)\log \hat{p}(y_i)$$
上式之所以取负，是因为概率为0-1，在log中是恒为负的，因此需要取反得正。那么在连加每个词表中得词的交叉熵时，VocabSize个词中只有$p(y_{true})$为1，其余为0。因此交叉熵损失实际可以简化为：
$$\text{Loss} = -p(y_{true})\log \hat{p}(y_{true})$$

使用交叉熵作为损失的概率合理性：权重的极大似然估计MLE隐含交叉熵损失形式

# 3 相对熵：KL散度，非负差异
KL散度（Kullback-Leibler Divergence）是衡量两个概率分布p(x)和q(x)之间的差异的度量，又称为相对熵，前面提到。定义如下：
$$D_{KL}(p||q) = \sum_{i=1}^n p(y_i)\log \frac{p(y_i)}{q(y_i)}$$


## 3.2 KL散度非负性

KL散度具有非负性，当且仅当$p(x_i)=q(x_i)$时，KL散度为0。非负性证明如下，不等式处是log上凸函数遵循Jensen's inequality（詹森不等式）的结果：
$$D_{KL}(p||q) = \sum_{i=1}^n p(x_i)\log \frac{p(x_i)}{q(x_i)} = -\sum_{i=1}^n p(x_i)\log \frac{q(x_i)}{p(x_i)} \\
\geq -\log \sum_{i=1}^n p(x_i)\frac{q(x_i)}{p(x_i)} = -\log \sum_{i=1}^n q(x_i) \ge -\log 1 = 0
$$

此外，根据两个分布p和q的位置，KL散度还区分正向和反向。两者主要是对不同的策略模型采样，并都更加关注另一个策略在高概率区域的表现。
## 3.3 正向KL散度：对参考策略采样，鼓励新策略(分母)大胆
$$D_{KL}(p||q) = \sum_{i=1}^n p(y_i)\log \frac{p(y_i)}{q(y_i)}$$
对参考策略$p(y_i)或\pi_{ref}$进行采样，直觉上主要关注$\pi_{\theta}$是否覆盖了$\pi_{ref}$中的高概率区域（对p(yi)可能采样到高概率和低概率区域，对于低概率区域，q(yi)随便取什么都是低概率；对于高概率区域，q(yi)也只能为高概率来最优化。这就是主要关注新策略是否覆盖了参考策略中的高概率区域，而对是否覆盖低概率区域不敏感）。
该形式强调“探索”，倾向于避免低概率区域，因为p(yi)是固定的，要散度最小化只能增大q(yi)，即孤立模型更加激进，倾向于避免低概率区域（参考p的高概率区域q也要高概率，低概率区域也要尽可能高概率）。
## 3.4 反向KL散度：对新策略采样，孤立新策略(分子)保守
调换pq位置，如下
$$D_{KL}(q||p) = \sum_{i=1}^n q(y_i)\log \frac{q(y_i)}{p(y_i)}$$
对新策略$q(y_i)或\pi_{\theta}$进行采样，直觉上主要关注$\pi_{\theta}$的分布是否偏离了$\pi_{ref}$，但对$\pi_{ref}$中的低概率区域不敏感（因为不会从那里采用，或者说，当q(yi)本身就是低概率时，p(yi)是否低概率都无所谓；而当q(yi)为高概率时，就要求p(yi)也尽可能为高概率。这就是所谓的对低概率不敏感）。
该形式倾向于“保守”，因为p(yi)固定，倾向于让q(yi)小一点（散度越小越好），即对某些动作的概率小一点。对于本身就是小概率的区域，要更小；对于大概率区域，小一点总没错。

# 4 交叉熵与KL散度


## 4.1 熵=交叉熵+KL散度
可以看到，交叉熵和KL散度的公式非常接近，对于真实分布p(x)，以及对其的预测q(x)，我们可以将p(x)的熵写成两者交叉熵和KL散度的和，推导如下：

$$D_{KL}(p||q) = \sum_{i=1}^n p(y_i)\log \frac{p(y_i)}{q(y_i)} = \\
\sum_{i=1}^n p(y_i)(\log p(y_i) - \log q(y_i)) = \\
\sum_{i=1}^n (p(y_i)·\log p(y_i) - p(y_i)·\log q(y_i)) = \\
H(p)-H(p,q)
$$
## 4.2 KL散度与交叉熵损失选择

通过对熵、交叉熵和KL散度的推导，我们可以直到，对于任何真实分布p(x)的预测分布q(x)，只要q(x)不完全等于p(x)，就会使得两者的KL散度变大，也即交叉熵变大。因此，我们将优化目标定为最小化交叉熵损失或KL散度均可。那么这两个分别适用于什么场景呢？

**一言以蔽之，当真实分布固定时，最小化交叉熵等价于最小化KL散度。当两个分布都在变化或者不存在固定的真实分布时，使用KL散度。**

### 4.2.1 交叉熵场景：存在真实分布
交叉熵损失适用于经典的分类任务场景，这类场景有标签，即拥有真实分布

- 交叉熵计算更方便，工程实现更简单
- KL散度有冗余计算部分，即实际上，**相对熵（KL散度）= 熵 - 交叉熵**，如下KL散度在计算过程中实际上会先计算熵，再计算交叉熵，再相减得到KL散度。在功能一样的前提下交叉熵的计算更简单：

### 4.2.2 KL散度场景：不存在所谓真实分布
比较/约束两个任意分布时，用于分布拟合、变分推断、策略更新。例如在对齐微调DPO/强化学习中会进行**策略更新**，此时目标是新旧策略的差异保持在一个可以接受的范围内，这时KL散度可以作为一个正则化项，防止模型训练时极端更新。


# 5 权重更新：多元交叉熵的BP流程



## 5.1 两种权重更新方法
权重更新方法主要有迭代法（梯度下降）和直接法（牛顿法）两种：
- 梯度下降法（迭代法）：通过反向传播计算梯度并根据梯度更新参数。简单来说，它沿着目标函数的梯度方向，逐步调整权重，直到找到一个局部最优解。
    - 优点：计算效率高，简单易实现，适应性强。
    - 缺点：收敛速度慢，容易陷入局部最优，需要调参（如学习率）
- 牛顿法（直接法）：一种基于二阶优化的算法，它利用目标函数的 二阶导数（即海森矩阵）来加速优化过程。与梯度下降法不同，牛顿法不仅使用梯度信息，还使用了目标函数的曲率信息来指导参数更新。
    - 优点：收敛速度更快，无需手动调整学习率
    - 缺点：计算复杂度高，存储和内存消耗大，可能不适用于大规模问题

## 5.2 梯度下降法的BP反向传播

梯度是多变量微积分中的一个概念，用于表示一个多维函数在某一点上的最速上升方向和变化率。它是函数的偏导数的向量形式，广泛应用于优化问题，尤其是在机器学习和深度学习中。

具体而言，对于一个权重矩阵W，数据流经过其后得到的hidden_states经过激活函数f后可以用于计算损失L，然后计算L相对于每个权重的偏导数作为更新量，如下，输入x先经过W与隐状态激活后得到h，再将h输入输出层激活（多分类中为Softmax）得到预测值$\hat y$，最后用损失函数L计算得到损失值标量scalar Loss：
$$h = \text{f}(W·x) \\
\hat y = \text{Softmax}(h) \\
E = \text{CrossEntroty}(y, \hat y)
$$
上面过程为前向传播，获得损失Loss值后进行反向传播BP。在反向传播过程中逐层对之前所有的权重矩阵链式求偏导，分摊损失责任，并督促其进行梯度调整。例如，需要求E对于权重矩阵W的梯度，并取负（因为梯度是上升最大方向，取负为下降最大方向），如下，其中$\eta$是学习率：
$$
W_{new} = W-\eta\frac{\partial E}{\partial W}
$$

对于经典的二分类问题，常用二元交叉熵作为损失，并使用Sigmoid激活；而对于更复杂的多分类问题，如decoder-only模型的next token选择，则采用多元交叉熵作为损失。
下面介绍其BP流程。


## 5.3 公式推导

假设输入为x, 权重矩阵为W，激活函数为Softmax，损失函数是多元交叉熵（输出类别数为n）。

前向传播流程如下，其中由于y_j是one-hot向量，只有一个位置为1，所以损失大小只与网络判断正确分类的概率有关，可以简化。

$$
z = W·x+b, z=[z_1,z_2,...,z_n]\\
\hat y_j = \frac{e^{z_j}}{\sum_{k=1}^{n}e^{z_k}}, j = 1,2,..., n \\
L = -\sum_{j=1}^n y_j\log \hat y_j
$$

其中，n代表分类数量，$y_j$代表真实标签在第j个类上的值（0或1），$\hat y_j$代表模型对第j类的预测概率0-1。反向传播如下：

### 5.3.1 求损失L相对于Softmax输出$\hat y$的梯度
由于损失是标量，概率分布是一维向量，所以梯度也是一维向量，但只有一个位置有值(j=t真实处)，其余为0。
$$
\frac{\partial L}{\partial \hat y_j} = -\frac{y_j}{\hat y_j} \\

$$

### 5.3.2 计算$\hat y$对Logits（输入Softmax前的向量）$z$的梯度
由于两者都是长度为n的向量，因此两者求偏导会得到一个n*n的矩阵。对于任意$k,j\in[1,n]$，如下：

$$
\frac{\partial \hat y_j}{\partial z_j} = 

\frac{\partial}{\partial z_j}(\frac{e^{z_j}}{\sum_{k=1}^{n}e^{z_k}} )= 

\frac{e^{z_j}\sum_{k=1}^{n}e^{z_k} - e^{z_j}e^{z_j}}{(\sum_{k=1}^{n}e^{z_k})^2} =
$$
$$
\frac{e^{z_j}}{\sum_{k=1}^{n}e^{z_k}}·\frac{\sum_{k=1}^{n}e^{z_k} - e^{z_j}}{\sum_{k=1}^{n}e^{z_k}} = \frac{e^{z_j}}{\sum_{k=1}^{n}e^{z_k}}·(1-\frac{e^{z_j}}{\sum_{k=1}^{n}e^{z_k}}) = \hat y_j(1-\hat y_j)
$$


当k!=j时：
$$
\frac{\partial \hat y_j}{\partial z_k} = \frac{- e^{z_j}e^{z_k}}{(\sum_{k=1}^{n}e^{z_k})^2} = -\frac{e^{z_j}}{\sum_{k=1}^{n}e^{z_k}}·\frac{e^{z_k}}{\sum_{k=1}^{n}e^{z_k}} = -\hat y_j·\hat y_k
$$

因此，梯度矩阵，对角线上是$\hat y_j(1-\hat y_j)$，其他位置是$-\hat y_j·\hat y_k$。

### 5.3.3 结合1和2
链式求L对于$z$的偏导也是一个矩阵：
$$
\frac{\partial L}{\partial z} = \frac{\partial L}{\partial \hat y}·\frac{\partial \hat y}{\partial z}
$$
由于$y_j=1$，则当j=k时，
$$
\frac{\partial L}{\partial z_j} = -\frac{1}{\hat y_j}· \hat y_j(1-\hat y_j) =\hat y_j -1
$$
当j!=k时，
$$
\frac{\partial L}{\partial z_k} = -\frac{1}{\hat y_j}· -\hat y_j·\hat y_k = \hat y_k - 0
$$

两者形式可以统一，
$$
\frac{\partial L}{\partial z_j} = \hat y_j -y_j
$$
当j=t(为真实类别)时，梯度为$\hat y_t -1$，否则梯度为$\hat y_j - 0$

### 5.3.4 求W和b的梯度
求完损失对softmax的梯度后，就可以求解模型权重W（shape=[m,n]）和偏置b（shape=[n]）的偏导了，用于更新两者的值。本质上，需要每个$W_{i,j}权重值对损失L标量的影响。$由于$z$是一个长度为n的向量，所以对W的偏导是W的一行对应z的一个数值。

$$
\frac{\partial L}{\partial W_{i,j}} = \frac{\partial L}{\partial z_j}\frac{\partial z_j}{\partial W_{i,j}} 
$$
其中$\frac{\partial L}{\partial z_j}$已经在5.3.3中求出来了，为$\hat y_j -1$或者$\hat y_k$；后者则根据$z = W·x+b$可以如下求得

$$
\frac{\partial z_j}{\partial W_{i,j}} = x_i
$$

因此，组合起来就是
$$
\frac{\partial L}{\partial W_{i,j}} = (\hat y_j -y_j)·x_i = \Delta W_{i,j}
$$

由于梯度是上升方向，因此需要取负才表示下降。最终，梯度更新如下
$$
W_{new,i,j} = W_{i,j} -\eta\frac{\partial L}{\partial W_{i,j}} = W_{i,j} -\eta(\hat y_j -y_j)·x_i 
$$

类似的，偏置梯度如下

$$
\frac{\partial L}{\partial b_j} = \frac{\partial L}{\partial z_j}\frac{\partial z_j}{\partial b_j} = \frac{\partial L}{\partial z_j}·1=(\hat y_j -y_j)
$$